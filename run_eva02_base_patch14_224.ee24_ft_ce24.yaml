# === Model ===
model_arch: eva02_base_patch14_224.mim_in22k
model_type: timm

# === WandB ===
wandb_project: capsule_vision_challenge_2024  
entity: lakshminarayanan-

# === Dataset Paths ===
dataset_path: "/home/endodl/PHASE-1/mln/lesions_cv24/MAIN/data1/split_data_eva02"
# dataset_csv_path: "/home/endodl/PHASE-1/mln/lesions_cv24/MAIN/codes/capsule_vision_challenge_2024/datasets/ce24"
dataset_csv_path: "/home/endodl/PHASE-1/mln/lesions_cv24/MAIN/data1/split_data_eva02"

# === Checkpoints ===
# checkpoint_dir: "/home/endodl/PHASE-1/mln/lesions_cv24/MAIN/codes/capsule_vision_challenge_2024/checkpoints/run-20250514_163307-lunar-plasma-72"
pretrained_checkpoint_dir: "/home/endodl/PHASE-1/mln/lesions_cv24/MAIN/codes/capsule_vision_challenge_2024/pretrained_models_copy/"
checkpoint_filename: "/home/endodl/PHASE-1/mln/lesions_cv24/MAIN/codes/capsule_vision_challenge_2024/pretrained_models_copy/eva02_best_epoch14_val_recall_macro0.97.ckpt"

# === Transforms ===
transform_path: "/home/endodl/PHASE-1/mln/lesions_cv24/MAIN/codes/capsule_vision_challenge_2024/configs/transforms/base_transforms.py"

# === Training Parameters ===
max_epochs: 1
seed: 42
train_bs: 128
val_bs: 128
fold_id: 0 # Fold 0 is used for validation and fold 1 for training (see train_val.csv)
img_size: 224
num_workers: 8
ft_mode: full

# === Optimizer ===
lr: 1e-6
optimizer: adabelief
metric: val_recall_macro
weight_decay: 0.0002

# === Scheduler ===
scheduler: lambda
lambda_factor: 0.95
